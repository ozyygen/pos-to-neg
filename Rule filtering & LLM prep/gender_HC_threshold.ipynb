{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BgjOGH2ttnB"
      },
      "outputs": [],
      "source": [
        "#calculate discovered rules' confidence and head coverage scores\n",
        "import rdflib\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Step 1: extract facts as RDFLib graph\n",
        "def load_graph_from_nt(nt_file):\n",
        "    g = rdflib.Graph()\n",
        "    g.parse(nt_file, format=\"nt\")\n",
        "    return g\n",
        "\n",
        "# Step 2: Execute SPARQL for head and body match counts\n",
        "def execute_sparql(graph, sparql_query):\n",
        "    result = graph.query(sparql_query)\n",
        "    for row in result:\n",
        "        return int(row[0])\n",
        "    return 0\n",
        "\n",
        "# Step 3: Calculate metrics for each rule\n",
        "def calculate_metrics(rules_csv, graph, output_csv):\n",
        "    rules_df = pd.read_csv(rules_csv, sep=\"\\t\", header=None)\n",
        "\n",
        "    # Add new columns for metrics\n",
        "    rules_df['Support'] = 0\n",
        "    rules_df['Confidence'] = 0.0\n",
        "    rules_df['Head Coverage'] = 0.0\n",
        "\n",
        "    for index, row in rules_df.iterrows():\n",
        "        rule = row[3]  # Rule column\n",
        "\n",
        "        # Extract head and body patterns from the rule\n",
        "        head_match = re.search(r'(https?://[\\w\\./#-]+)\\(([^,]+),([^)]+)\\)\\s*<=', rule)\n",
        "        body_matches = re.findall(r'(https?://[\\w\\./#-]+)\\(([^,]+),([^)]+)\\)', rule.split('<=')[1] if '<=' in rule else '')\n",
        "\n",
        "        if not head_match or not body_matches:\n",
        "            continue\n",
        "\n",
        "        head_predicate = head_match.group(1)\n",
        "        head_arg1 = head_match.group(2)\n",
        "        head_arg2 = head_match.group(3)\n",
        "\n",
        "        # Replace \"X\" with \"?X\" for variables\n",
        "        if head_arg1 == \"X\":\n",
        "            head_arg1 = \"?X\"\n",
        "        else:\n",
        "            head_arg1 = f\"<{head_arg1}>\"\n",
        "\n",
        "        if head_arg2 == \"X\":\n",
        "            head_arg2 = \"?X\"\n",
        "        else:\n",
        "            head_arg2 = f\"<{head_arg2}>\"\n",
        "\n",
        "\n",
        "\n",
        "        # Extract body components and replace \"X\" with \"?X\" for variables\n",
        "        body_predicate = body_matches[0][0]\n",
        "        body_arg1 = body_matches[0][1]\n",
        "        body_arg2 = body_matches[0][2]\n",
        "\n",
        "        if body_arg1 == \"X\":\n",
        "            body_arg1 = \"?X\"\n",
        "        else:\n",
        "            body_arg1 = f\"<{body_arg1}>\"\n",
        "\n",
        "        if body_arg2 == \"X\":\n",
        "            body_arg2 = \"?X\"\n",
        "        else:\n",
        "            body_arg2 = f\"<{body_arg2}>\"\n",
        "\n",
        "        # SPARQL query for counting body & head matches\n",
        "        body_sparql = f\"\"\"\n",
        "        SELECT (COUNT(*) AS ?bodyMatchCount)\n",
        "        WHERE {{\n",
        "          {body_arg1} <{body_predicate}> {body_arg2} .\n",
        "          {head_arg1} <{head_predicate}> {head_arg2} .\n",
        "        }}\n",
        "        \"\"\"\n",
        "        total_b_h_matches = execute_sparql(graph, body_sparql)\n",
        "\n",
        "        # SPARQL query for counting body matches (positive examples)\n",
        "        head_sparql = f\"\"\"\n",
        "        SELECT (COUNT(*) AS ?headMatchCount)\n",
        "        WHERE {{\n",
        "\n",
        "          {body_arg1} <{body_predicate}> {body_arg2} .\n",
        "        }}\n",
        "        \"\"\"\n",
        "        total_b_matches  = execute_sparql(graph, head_sparql)\n",
        "        body_sparql = f\"\"\"\n",
        "        SELECT (COUNT(*) AS ?bodyMatchCount)\n",
        "        WHERE {{\n",
        "          {body_arg1} <{body_predicate}> {body_arg2} .\n",
        "          {head_arg1} <{head_predicate}> ?w .\n",
        "        }}\n",
        "        \"\"\"\n",
        "        total_b_pca_matches = execute_sparql(graph, body_sparql)\n",
        "\n",
        "        body_sparql = f\"\"\"\n",
        "        SELECT (COUNT(*) AS ?bodyMatchCount)\n",
        "        WHERE {{\n",
        "          {head_arg1} <{head_predicate}> ?w .\n",
        "        }}\n",
        "        \"\"\"\n",
        "        total_h_r_matches = execute_sparql(graph, body_sparql)\n",
        "        # Calculate metrics\n",
        "\n",
        "        confidence = total_b_h_matches / total_b_matches if total_b_h_matches > 0 else 0\n",
        "        head_coverage = total_b_h_matches / total_h_r_matches if total_h_r_matches > 0 else 0\n",
        "        # Update the DataFrame\n",
        "        rules_df.at[index, 'Support'] = total_b_h_matches\n",
        "        rules_df.at[index, 'Confidence'] = confidence\n",
        "        rules_df.at[index, 'Head Coverage'] = head_coverage\n",
        "\n",
        "    rules_df.to_csv(output_csv, sep=\"\\t\", index=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    nt_file_path = 'path/to/MIMIC_non-code.nt'\n",
        "    rules_csv_path = \"path/to/output_1.0-0.99.csv\"\n",
        "    output_csv_path = \"path/to/output_rules_with_metrics_1.0-0.99_new.csv\"\n",
        "\n",
        "    graph = load_graph_from_nt(nt_file_path)\n",
        "\n",
        "    # Calculate metrics and update the rules CSV file\n",
        "    calculate_metrics(rules_csv_path, graph, output_csv_path)\n",
        "\n",
        "    print(f\"Metrics calculated and saved to {output_csv_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElJSZlqBBgu2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def analyze_head_coverage_thresholds(df, hc_col, quantile_range=(80, 100)):\n",
        "    \"\"\"\n",
        "    Analyze rule filtering based on Head Coverage quantile thresholds and plot results.\n",
        "    \"\"\"\n",
        "    print(df.info())\n",
        "    hc_series = df[hc_col]\n",
        "    hc_filtered = hc_series[(hc_series != 0.0) & (~hc_series.isna())]\n",
        "\n",
        "\n",
        "\n",
        "    # Create quantile steps\n",
        "\n",
        "    quantiles = [q / 100 for q in range(80, 100)]\n",
        "    thresholds = [hc_filtered.quantile(q) for q in quantiles]\n",
        "\n",
        "\n",
        "    # Create results DataFrame\n",
        "    df_plot = pd.DataFrame({\n",
        "        'Quantile': quantiles,\n",
        "        'Threshold': thresholds\n",
        "    })\n",
        "\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.plot(df_plot['Quantile'], df_plot['Threshold'], marker='o')\n",
        "    plt.title('Head Coverage Thresholds by Quantile')\n",
        "    plt.xlabel('Quantile')\n",
        "    plt.ylabel('HC Threshold')\n",
        "    plt.grid(True)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"path/to/hc_thresh.svg\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    return df_plot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QR6Aje_6B7QR"
      },
      "outputs": [],
      "source": [
        "#analyse HC thresholds of test set\n",
        "df =  pd.read_csv(\"path/to/test_file.csv\", sep='\\t')\n",
        "results = analyze_head_coverage_thresholds(df, hc_col='0.0.1_int')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-7GR5EaBzmV"
      },
      "outputs": [],
      "source": [
        "#find f-score of valid set\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "desired_rules_path = \"path/to/valid_file.csv\"\n",
        "all_rules_path = \"path/to/output_rules_with_metrics_1.0-0.98.csv\"\n",
        "df_desired = pd.read_csv(desired_rules_path, sep=\"\\t\")\n",
        "df_all = pd.read_csv(all_rules_path, sep=\"\\t\",skiprows=[1])\n",
        "\n",
        "# Validate columns\n",
        "hc_col = '0.0.1_int'\n",
        "df_desired.rename(columns={\"rule\": \"3\"}, inplace=True)\n",
        "\n",
        "match_cols = ['3']  # column(s) used to identify rule match\n",
        "\n",
        "if hc_col not in df_desired.columns or hc_col not in df_all.columns:\n",
        "    raise ValueError(f\"Missing '{hc_col}' in one of the files.\")\n",
        "for col in match_cols:\n",
        "    if col not in df_desired.columns or col not in df_all.columns:\n",
        "        raise ValueError(f\"Column '{col}' missing in one of the files.\")\n",
        "\n",
        "# Generate quantile thresholds\n",
        "quantiles = [q / 100 for q in range(80, 100)]\n",
        "thresholds = [df_all[hc_col].quantile(q) for q in quantiles]\n",
        "\n",
        "# Compute recall for each threshold\n",
        "recall_values = []\n",
        "\n",
        "print(\"=== Recall per Threshold ===\")\n",
        "for q, thresh in zip(quantiles, thresholds):\n",
        "    df_desired_filtered = df_desired[df_desired[hc_col] > thresh]\n",
        "    df_all_filtered = df_all[df_all[hc_col] > thresh]\n",
        "\n",
        "    if df_desired_filtered.empty:\n",
        "        recall_values.append(0)\n",
        "        print(f\"Quantile {q:.2f} | Threshold: {thresh} | No desired rules above threshold â†’ Recall: 0.0000\")\n",
        "        continue\n",
        "\n",
        "    merged = pd.merge(df_all_filtered, df_desired_filtered, on=match_cols, how='inner')\n",
        "    matching_count = len(merged)\n",
        "\n",
        "    recall = matching_count / len(df_desired)\n",
        "    recall_values.append(recall)\n",
        "\n",
        "    print(\n",
        "        f\"Quantile {q:.2f} | Threshold: {thresh} | \"\n",
        "        f\"Relevant rule count in all rules: {matching_count} | \"\n",
        "        f\"All relevant rules' count: {len(df_desired)} | Recall: {recall:.4f}\"\n",
        "    )\n",
        "\n",
        "# Plotting\n",
        "range_labels = [str(t) for t in thresholds]\n",
        "\n",
        "# Create bar chart\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(range_labels, recall_values, color='coral')\n",
        "\n",
        "# Axis labels and title\n",
        "plt.xlabel(\"Head Coverage Threshold\")\n",
        "plt.ylabel(\"Recall\")\n",
        "plt.title(\"Recall by Head Coverage Threshold\")\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "\n",
        "# Format Y-axis to always show 4 digits after the decimal\n",
        "plt.gca().yaxis.set_major_formatter(ticker.FormatStrFormatter('%.2f'))\n",
        "\n",
        "\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
