{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping invalid line: \n",
      "Skipping invalid line: \n",
      "Turtle file generated: /Users/ozgeerten/Documents/GitHub/rudik-docker/Codex/codexM-output.ttl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import rdflib\n",
    "\n",
    "# Define a base namespace for all URIs\n",
    "EXAMPLE_NS = rdflib.Namespace(\"http://example.org/\")\n",
    "WIKIDATA_NS = rdflib.Namespace(\"http://www.wikidata.org/entity/\")\n",
    "PREDICATE_NS = rdflib.Namespace(\"http://www.wikidata.org/prop/direct/\")\n",
    "\n",
    "def load_json(file_path):\n",
    "    \"\"\"Load a JSON file and return its content as a dictionary.\"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def parse_spo_file(spo_file_path):\n",
    "    \"\"\"Parse a tab-separated subject-predicate-object file.\"\"\"\n",
    "    triples = []\n",
    "    with open(spo_file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) == 3:\n",
    "                subject, predicate, obj = parts\n",
    "                triples.append((subject, predicate, obj))\n",
    "            else:\n",
    "                # Optionally, log or print the problematic line for debugging\n",
    "                print(f\"Skipping invalid line: {line.strip()}\")\n",
    "    return triples\n",
    "\n",
    "def generate_ttl(triples, entity_data, relation_data, type_data, entity2type_data, output_ttl_path):\n",
    "    \"\"\"Generate a TTL file based on triples and additional info from JSON files.\"\"\"\n",
    "    g = rdflib.Graph()\n",
    "\n",
    "    for subj, pred, obj in triples:\n",
    "        # Create RDF triples using the base namespace\n",
    "        subject_uri = WIKIDATA_NS[subj]\n",
    "        predicate_uri = PREDICATE_NS[pred]\n",
    "        object_uri = WIKIDATA_NS[obj]\n",
    "\n",
    "        g.add((subject_uri, predicate_uri, object_uri))\n",
    "\n",
    "        # Add label and type link for subject\n",
    "        if subj in entity_data:\n",
    "            label = entity_data[subj].get('label', '')\n",
    "            \n",
    "            if label:\n",
    "                g.add((subject_uri, rdflib.RDFS.label, rdflib.Literal(label)))\n",
    "    \n",
    "        # Add label and type link for object\n",
    "        if obj in entity_data:\n",
    "            label = entity_data[obj].get('label', '')\n",
    "            \n",
    "            if label:\n",
    "                g.add((object_uri, rdflib.RDFS.label, rdflib.Literal(label)))\n",
    "\n",
    "        # Add label for predicate\n",
    "        if pred in relation_data:\n",
    "            pred_label = relation_data[pred].get('label', '')\n",
    "            if pred_label:\n",
    "                g.add((predicate_uri, rdflib.RDFS.label, rdflib.Literal(pred_label)))\n",
    "\n",
    "    # Add type relations using P31 from entity2type data\n",
    "    for entity, types in entity2type_data.items():\n",
    "        entity_uri = WIKIDATA_NS[entity]\n",
    "        for entity_type in types:\n",
    "            type_uri = WIKIDATA_NS[entity_type]\n",
    "            g.add((entity_uri, PREDICATE_NS['P31'], type_uri))\n",
    "\n",
    "    # Serialize the graph to a Turtle file\n",
    "    g.serialize(destination=output_ttl_path, format='turtle')\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    # Input file paths\n",
    "    entity_json_path = \"/Users/ozgeerten/Documents/GitHub/codex/data/entities/en/entities.json\"\n",
    "    relation_json_path = \"/Users/ozgeerten/Documents/GitHub/codex/data/relations/en/relations.json\"\n",
    "    type_json_path = \"/Users/ozgeerten/Documents/GitHub/codex/data/types/en/types.json\"\n",
    "    entity2type_json_path = \"/Users/ozgeerten/Documents/GitHub/codex/data/types/entity2types.json\"\n",
    "    spo_file_path = \"/Users/ozgeerten/Documents/GitHub/codex/data/triples/codex-m/graph.txt\"\n",
    "    output_ttl_path = \"/Users/ozgeerten/Documents/GitHub/rudik-docker/Codex/codexM-output.ttl\"\n",
    "\n",
    "    # Load JSON data\n",
    "    entity_data = load_json(entity_json_path)\n",
    "    relation_data = load_json(relation_json_path)\n",
    "    type_data = load_json(type_json_path)\n",
    "    entity2type_data = load_json(entity2type_json_path)\n",
    "\n",
    "    # Parse the SPO file\n",
    "    triples = parse_spo_file(spo_file_path)\n",
    "\n",
    "    # Generate TTL file\n",
    "    generate_ttl(triples, entity_data, relation_data, type_data, entity2type_data, output_ttl_path)\n",
    "\n",
    "    print(f\"Turtle file generated: {output_ttl_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: http://www.wikidata.org/entity/Q188451, Count: 5597\n",
      "Subject: http://www.wikidata.org/entity/Q201658, Count: 4346\n",
      "Subject: http://www.wikidata.org/entity/Q11424, Count: 2507\n",
      "Subject: http://www.wikidata.org/entity/Q373342, Count: 2189\n",
      "Subject: http://www.wikidata.org/entity/Q223393, Count: 1041\n",
      "Subject: http://www.wikidata.org/entity/Q11399, Count: 1041\n",
      "Subject: http://www.wikidata.org/entity/Q4263830, Count: 843\n",
      "Subject: http://www.wikidata.org/entity/Q21010853, Count: 801\n",
      "Subject: http://www.wikidata.org/entity/Q37073, Count: 755\n",
      "Subject: http://www.wikidata.org/entity/Q483394, Count: 750\n"
     ]
    }
   ],
   "source": [
    "# Load the RDF graph from the Turtle file\n",
    "g = rdflib.Graph()\n",
    "g.parse(output_ttl_path, format=\"turtle\")\n",
    "\n",
    "# Define a SPARQL query as a string\n",
    "sparql_query = \"\"\"\n",
    "SELECT ?o (COUNT(?o) AS ?c)\n",
    "WHERE {\n",
    "    ?s1 <http://www.wikidata.org/prop/direct/P136> ?o1.\n",
    "    ?o1 <http://www.wikidata.org/prop/direct/P31> ?o .\n",
    "}\n",
    "GROUP BY ?o\n",
    "ORDER BY DESC(?c)\n",
    "LIMIT 10\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SPARQL query on the graph\n",
    "query_result = g.query(sparql_query)\n",
    "\n",
    "# Iterate through the results and print them\n",
    "for row in query_result:\n",
    "    print(f\"Subject: {row.o}, Count: {row.c}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
